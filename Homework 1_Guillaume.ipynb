{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_FOLDER = '../../ADA2017-Tutorials/02 - Intro to Pandas/Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "PATH_SEPARATOR = '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to go through each folders in the ebola folder and for each one, concatenate all the CSV into a single dataframe.\n",
    "We need to join the file, but, as we don't have the same column in every files, we need to merge/fills columns from one file to another.\n",
    "This is exactly what the append method of a DataFrame does, it merges columns and fill empty cell with NaN.\n",
    "\n",
    "At the end of this operation, we'll be in possession of a single DataFrame for the whole contries.\n",
    "Another choice we made was to make `date` and `Description`, `Variable`, `variable` column as indexes. This is a detail, but it simplifies the sum over the columns (indexes are not part of columns), and the `.loc` method is more readable when addressing indexes.\n",
    "\n",
    "The next step was to filter the interessting rows with respect to the labels, as they are different in each contry but can also be different from one file to another we need handles more that one label per country.\n",
    "Once the rows were fileterd with respect to the labels, we need to sum, for each day all the columns (that represents cities in the country), this is done by keeping only columns that are numbers and add them up.\n",
    "\n",
    "For each country, we can then return an array of data, representing the number of cases each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = DATA_FOLDER + PATH_SEPARATOR + \"ebola\"\n",
    "COUNTRY_FOLDERS = ['guinea_data', 'sl_data', 'liberia_data']\n",
    "COUNTRY_INDEXES = [['Description', 'Date'], ['variable', 'date'], ['Variable', 'Date']]\n",
    "COUNTRY_GROUP = ['Date', 'date', 'Date']\n",
    "COUNTRY_NEW_CASES_LABELS= [['New cases of confirmed'], ['new_confirmed'], ['New case/s (confirmed)']]\n",
    "COUNTRY_DEATH_LABELS= [['New deaths registered today (confirmed)', 'New deaths registered'], ['etc_new_deaths'], ['Newly reported deaths']]\n",
    "\n",
    "def compute(country_folder, indexes=[]):\n",
    "    country_folder = FOLDER + PATH_SEPARATOR + country_folder\n",
    "    files = listdir(country_folder)\n",
    "\n",
    "    dfs = [pd.read_csv(country_folder + PATH_SEPARATOR + file, index_col=indexes) for file in files]\n",
    "    assert(len(dfs) > 0)\n",
    "    result = dfs[0].append(dfs[1:])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_per_day(df, group):\n",
    "    assert(df.empty == False)\n",
    "    df = df.set_index([group])\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    grouped = df.groupby(pd.TimeGrouper(\"m\"))\n",
    "\n",
    "    s = grouped[0].mean()\n",
    "    s.index = s.index.map(lambda x: x.strftime('%Y-%m'))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_for_label(df, group, labels = []):\n",
    "    sum = pd.DataFrame()\n",
    "    for label in labels:\n",
    "        rows = df.loc[label].apply(pd.to_numeric, errors='ignore')\n",
    "        filtered = rows.select_dtypes(include=[np.number])\n",
    "        grouped = filtered.sum(axis=1).groupby(group)\n",
    "        sum = sum.append(grouped.sum().reset_index(), ignore_index=True) #Â Sum cities first then group by date\n",
    "    return average_per_day(sum, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average number of new cases per days</th>\n",
       "      <th>Average number of deaths per day</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-08</th>\n",
       "      <td>12.400000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09</th>\n",
       "      <td>12.562500</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08</th>\n",
       "      <td>19.600000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09</th>\n",
       "      <td>36.275862</td>\n",
       "      <td>3.481481</td>\n",
       "      <td>sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10</th>\n",
       "      <td>57.535714</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11</th>\n",
       "      <td>69.894737</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12</th>\n",
       "      <td>54.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06</th>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07</th>\n",
       "      <td>1.818182</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08</th>\n",
       "      <td>8.166667</td>\n",
       "      <td>23.222222</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09</th>\n",
       "      <td>6.166667</td>\n",
       "      <td>37.608696</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10</th>\n",
       "      <td>1.476190</td>\n",
       "      <td>28.120000</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>15.769231</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12</th>\n",
       "      <td>2173.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liberia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Average number of new cases per days  \\\n",
       "2014-08                             12.400000   \n",
       "2014-09                             12.562500   \n",
       "2014-10                              6.000000   \n",
       "2014-08                             19.600000   \n",
       "2014-09                             36.275862   \n",
       "2014-10                             57.535714   \n",
       "2014-11                             69.894737   \n",
       "2014-12                             54.333333   \n",
       "2014-06                              2.142857   \n",
       "2014-07                              1.818182   \n",
       "2014-08                              8.166667   \n",
       "2014-09                              6.166667   \n",
       "2014-10                              1.476190   \n",
       "2014-11                              9.500000   \n",
       "2014-12                           2173.875000   \n",
       "\n",
       "         Average number of deaths per day  Country  \n",
       "2014-08                          3.200000   guinea  \n",
       "2014-09                          3.800000   guinea  \n",
       "2014-10                         15.000000   guinea  \n",
       "2014-08                          4.100000       sl  \n",
       "2014-09                          3.481481       sl  \n",
       "2014-10                          4.142857       sl  \n",
       "2014-11                          1.500000       sl  \n",
       "2014-12                               NaN       sl  \n",
       "2014-06                          1.857143  liberia  \n",
       "2014-07                          4.272727  liberia  \n",
       "2014-08                         23.222222  liberia  \n",
       "2014-09                         37.608696  liberia  \n",
       "2014-10                         28.120000  liberia  \n",
       "2014-11                         15.769231  liberia  \n",
       "2014-12                               NaN  liberia  "
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "for i in range(len(COUNTRY_FOLDERS)):\n",
    "    df = compute(COUNTRY_FOLDERS[i], COUNTRY_INDEXES[i])\n",
    "    # There are two ways here, either we remove total and sums the colums, or we could only use total, assuming that it's correctly computed\n",
    "    if 'Totals' in df.columns.values:\n",
    "        del df['Totals']\n",
    "        \n",
    "    if 'National' in df.columns.values:\n",
    "        del df['National']\n",
    "    \n",
    "    new_cases = average_for_label(df, COUNTRY_GROUP[i], COUNTRY_NEW_CASES_LABELS[i])\n",
    "    deaths = average_for_label(df, COUNTRY_GROUP[i], COUNTRY_DEATH_LABELS[i])\n",
    "    labels = new_cases.map(lambda x: COUNTRY_FOLDERS[i].split('_')[0])\n",
    "    \n",
    "    result = result.append(pd.concat([new_cases, deaths, labels], axis=1))\n",
    "\n",
    "result.columns = ['Average number of new cases per days', 'Average number of deaths per day', 'Country']\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BARCODE</td>\n",
       "      <td>GROUP</td>\n",
       "      <td>SAMPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MID1</td>\n",
       "      <td>EXTRACTION CONTROL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MID2</td>\n",
       "      <td>NEC 1</td>\n",
       "      <td>tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MID3</td>\n",
       "      <td>Control 1</td>\n",
       "      <td>tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MID4</td>\n",
       "      <td>NEC 2</td>\n",
       "      <td>tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MID5</td>\n",
       "      <td>Control 2</td>\n",
       "      <td>tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MID6</td>\n",
       "      <td>NEC 1</td>\n",
       "      <td>stool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MID7</td>\n",
       "      <td>Control 1</td>\n",
       "      <td>stool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MID8</td>\n",
       "      <td>NEC 2</td>\n",
       "      <td>stool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MID9</td>\n",
       "      <td>Control 2</td>\n",
       "      <td>stool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                   1       2\n",
       "0  BARCODE               GROUP  SAMPLE\n",
       "1     MID1  EXTRACTION CONTROL     NaN\n",
       "2     MID2               NEC 1  tissue\n",
       "3     MID3           Control 1  tissue\n",
       "4     MID4               NEC 2  tissue\n",
       "5     MID5           Control 2  tissue\n",
       "6     MID6               NEC 1   stool\n",
       "7     MID7           Control 1   stool\n",
       "8     MID8               NEC 2   stool\n",
       "9     MID9           Control 2   stool"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = DATA_FOLDER + PATH_SEPARATOR + \"microbiome\"\n",
    "PREFIX = \"MID\"\n",
    "NUMBER = 9\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in range(1, NUMBER+1):\n",
    "    result = result.append(pd.read_excel(FOLDER + PATH_SEPARATOR + f\"MID{i}.xls\", sheetname='Sheet 1', header=None))\n",
    "\n",
    "header = pd.read_excel(FOLDER + PATH_SEPARATOR + \"metadata.xls\", sheetname='Sheet1', header=None)\n",
    "    \n",
    "result.fillna('unknown')\n",
    "header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd0 in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-822-636e851c1162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/titanic.xls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/titanic.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:6175)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header (pandas/_libs/parsers.c:9691)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd0 in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "df = pd.read_csv(DATA_FOLDER+'/titanic.xls')\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
