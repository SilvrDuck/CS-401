{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/Users/noodle/workspace/python/ADA/tutorials/ADA2017-Tutorials/02 - Intro to Pandas/Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            guinea  liberia   sl\n",
      "2014-06-16     0.0      2.0  0.0\n",
      "2014-06-17     0.0      0.0  0.0\n",
      "2014-06-22     0.0     10.0  0.0\n",
      "2014-06-24     0.0      8.0  0.0\n",
      "2014-06-25     0.0      4.0  0.0\n",
      "2014-06-28     0.0      2.0  0.0\n",
      "2014-06-29     0.0      4.0  0.0\n",
      "2014-07-01     0.0      4.0  0.0\n",
      "2014-07-02     0.0      0.0  0.0\n",
      "2014-07-03     0.0      2.0  0.0\n",
      "2014-07-07     0.0     10.0  0.0\n",
      "2014-07-08     0.0      0.0  0.0\n",
      "2014-07-10     0.0      0.0  0.0\n",
      "2014-07-13     0.0      0.0  0.0\n",
      "2014-07-17     0.0      0.0  0.0\n",
      "2014-07-20     0.0      2.0  0.0\n",
      "2014-07-24     0.0     10.0  0.0\n",
      "2014-07-26     0.0     12.0  0.0\n",
      "2014-08-02     0.0      0.0  0.0\n",
      "2014-08-04     0.0      2.0  0.0\n",
      "2014-08-12     0.0      4.0  0.0\n",
      "2014-08-13     0.0      0.0  0.0\n",
      "2014-08-14     0.0      0.0  0.0\n",
      "2014-08-15     0.0      8.0  0.0\n",
      "2014-08-16     0.0      0.0  0.0\n",
      "2014-08-17     0.0      0.0  0.0\n",
      "2014-08-18     0.0      4.0  0.0\n",
      "2014-08-19     0.0      0.0  0.0\n",
      "2014-08-20     0.0     36.0  0.0\n",
      "2014-08-21     0.0      0.0  0.0\n",
      "...            ...      ...  ...\n",
      "2014-11-08     0.0      0.0  0.0\n",
      "2014-11-10     0.0      0.0  0.0\n",
      "2014-11-12     0.0      0.0  0.0\n",
      "2014-11-13     0.0      0.0  0.0\n",
      "2014-11-14     0.0      0.0  0.0\n",
      "2014-11-15     0.0      0.0  0.0\n",
      "2014-11-16     0.0      0.0  0.0\n",
      "2014-11-17     0.0      0.0  0.0\n",
      "2014-11-18     0.0      0.0  0.0\n",
      "2014-11-19     0.0      0.0  0.0\n",
      "2014-11-20     0.0      0.0  0.0\n",
      "2014-11-21     0.0      0.0  0.0\n",
      "2014-11-22     0.0      0.0  0.0\n",
      "2014-11-23     0.0      0.0  0.0\n",
      "2014-11-24     0.0      0.0  0.0\n",
      "2014-11-26     0.0      0.0  0.0\n",
      "2014-11-27     0.0     24.0  0.0\n",
      "2014-11-28     0.0     14.0  0.0\n",
      "2014-11-29     0.0     19.0  0.0\n",
      "2014-11-30     0.0     20.0  0.0\n",
      "2014-12-01     0.0      2.0  0.0\n",
      "2014-12-02     0.0     18.0  0.0\n",
      "2014-12-03     0.0      0.0  0.0\n",
      "2014-12-04     0.0   5734.0  0.0\n",
      "2014-12-05     0.0   5734.0  0.0\n",
      "2014-12-06     0.0   5757.0  0.0\n",
      "2014-12-07     0.0   5757.0  0.0\n",
      "2014-12-08     0.0   5853.0  0.0\n",
      "2014-12-09     0.0   5891.0  0.0\n",
      "2014-12-13     0.0      0.0  0.0\n",
      "\n",
      "[135 rows x 3 columns]\n",
      "########################## NEW CASES ##########################\n",
      "           guinea      liberia        sl\n",
      "2014 6   0.000000     4.285714  0.000000\n",
      "     7   0.000000     3.636364  0.000000\n",
      "     8   0.000000     4.454545  0.000000\n",
      "     9   0.033333     9.866667  0.000000\n",
      "     10  0.000000     2.166667  9.433333\n",
      "     11  0.000000     3.080000  0.000000\n",
      "     12  0.000000  3474.600000  0.000000\n",
      "########################## DEATH ##########################\n",
      "         guinea     liberia         sl\n",
      "2014 6      0.0   34.285714   0.000000\n",
      "     7      0.0   86.545455   0.000000\n",
      "     8      0.0  160.181818   0.000000\n",
      "     9      0.0  970.800000   0.000000\n",
      "     10     0.0  465.258065  45.741935\n",
      "     11     0.0    0.000000   0.000000\n",
      "     12     0.0    0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Write your answer here\n",
    "\n",
    "\"\"\"\n",
    "Concate csv from the given directory and return a dataframe\n",
    "\"\"\"\n",
    "def concatData(fromFolder):\n",
    "    csvPath = [f for f in listdir(fromFolder) if isfile(join(fromFolder, f))]\n",
    "    csvPath = filter(lambda path: \".csv\" in path, csvPath)\n",
    "    csvPath = map(lambda pathFile: fromFolder + pathFile, csvPath)\n",
    "    dataFrames = map(pd.DataFrame.from_csv, csvPath)\n",
    "\n",
    "    return pd.concat(dataFrames)\n",
    "\n",
    "\"\"\"\n",
    "filter rows and clean dataset\n",
    "\"\"\"\n",
    "def cleanAndReturn(dataframe, variableName, variableValue, globalIndexName):\n",
    "    myDf = dataframe[dataframe[variableName] == variableValue]\n",
    "    myDf = myDf.fillna(value=0)\n",
    "    del myDf[variableName]\n",
    "    myDf.columns = pd.MultiIndex.from_tuples([i for i in map( lambda cN: (globalIndexName, cN), myDf.columns)])\n",
    "    myDf.index = map(lambda d: pd.to_datetime(d,infer_datetime_format=True, errors='coerce'), myDf.index)\n",
    "    \n",
    "    return myDf\n",
    "    \n",
    "\"\"\" avg daily per month \"\"\"\n",
    "def averageDailyPerMonth(serie):\n",
    "    notNanValues = serie[serie.notnull()]\n",
    "    if notNanValues.size == 0 : \n",
    "        return 'NC'\n",
    "    else:\n",
    "        return notNanValues.sum()/notNanValues.size\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\" I/ build & concatenate the dataset\"\"\"\n",
    "\n",
    "\"\"\" NOT EXISTENT VALUES ARE CONSIDERED AS 0 INSIDE A COUNTRY (if one register not null : others null <=> 0)\"\"\"\n",
    "\n",
    "guinea = concatData(DATA_FOLDER+\"/ebola/guinea_data/\")\n",
    "guinea_new_case = cleanAndReturn(guinea,'Description', 'New cases of confirmed', 'guinea');\n",
    "guinea_death = cleanAndReturn(guinea,'Description', 'Total deaths of confirmed', 'guinea');\n",
    "\n",
    "liberia = concatData(DATA_FOLDER+\"/ebola/liberia_data/\")\n",
    "liberia_new_case = cleanAndReturn(liberia,'Variable', 'New case/s (confirmed)', 'liberia');\n",
    "liberia_death = cleanAndReturn(liberia,'Variable', 'Total death/s in confirmed cases', 'liberia');\n",
    "\n",
    "sl = concatData(DATA_FOLDER+\"/ebola/sl_data/\")\n",
    "sl_new_case = cleanAndReturn(sl,'variable', 'new_confirmed', 'sl');\n",
    "sl_death = cleanAndReturn(sl,'variable', 'death_confirmed', 'sl');\n",
    "\n",
    "\n",
    "\"\"\" II/ merge and fill 0 for date that are not existing in all three countries\"\"\"\n",
    "\n",
    "new_cases = guinea_new_case.join(liberia_new_case, how='outer').join(sl_new_case, how='outer')\n",
    "deaths = guinea_death.join(liberia_death, how='outer').join(sl_death, how='outer')\n",
    "\n",
    "\n",
    "\"\"\" NOT EXISTENT VALUES ARE CONSIDERED AS MISSING VALUES FOR DATE ADDED DURING THE JOIN \"\"\"\n",
    "\"\"\"new_cases = new_cases.fillna(value=0)\"\"\"\n",
    "\"\"\"deaths = deaths.fillna(value=0)\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" III/ merge axis 1 (by region) and sum \"\"\"\n",
    "\n",
    "new_cases = new_cases.sum(axis=1, level=0)\n",
    "deaths = deaths.sum(axis=1, level=0)\n",
    "\n",
    "print(new_cases)\n",
    "\n",
    "\"\"\" IV/ merge axis 0 (by month) and take mean\"\"\"\n",
    "\n",
    "new_case_month_daily = new_cases.groupby([(new_cases.index.year),(new_cases.index.month)]).agg(averageDailyPerMonth)\n",
    "death_month_daily = deaths.groupby([(deaths.index.year),(deaths.index.month)]).agg(averageDailyPerMonth)\n",
    "\n",
    "\n",
    "\"\"\"V/ Print result\"\"\"\n",
    "\n",
    "print(\"########################## NEW CASES ##########################\")\n",
    "print(new_case_month_daily)\n",
    "\n",
    "print(\"########################## DEATH ##########################\")\n",
    "print(death_month_daily)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
